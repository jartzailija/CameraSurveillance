/**
* Idea got from http://www.pyimagesearch.com/2015/06/01/home-surveillance-and-motion-detection-with-the-raspberry-pi-python-and-opencv/
* This program detects movement, and shoots photos until movement has stopped.
* Photos are saved to images -folder as .jpg and files are named by unix time stamp
* and names are printed to the std output stream
*
* TODO: set parameters like saving folder as cmdline parameter
*
* Uses C++11 -standard
* Made by Jari Tolkki - jartzailija
*/

#include "opencv2/imgcodecs.hpp"
#include "opencv2/imgproc.hpp"
#include <opencv2/highgui.hpp>
#include <opencv2/video.hpp>
#include <iostream>
#include <chrono>
#include <unistd.h>
#include <raspicam/raspicam_cv.h>

using namespace cv;
using namespace std;

// Global variables
Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
bool firstFrameEncountered;
bool isFilmingMode;
raspicam::RaspiCam_Cv Camera;
int normalSleepTime;
int filmingSleepTime;
int recordTime = 0.1;
unsigned long detectionTime;
unsigned long startingTime;
int detectionArea;

//Functions
void run();
Mat shootImage();
void saveImage(Mat frame);
bool checkFrame(Mat frame);
unsigned long getEpochTime();

int main(int argc, char* argv[])
{
	//TODO: Set parameters as cmd line arguments
	Camera.set(CV_CAP_PROP_FRAME_WIDTH, 640);
	Camera.set(CV_CAP_PROP_FRAME_HEIGHT, 480);
	firstFrameEncountered = false;
	isFilmingMode = false;

	//When comparing images the system notices differences between them,
	//this is minimal area (x*y) as pixels to start filming
	detectionArea = 15000;

	startingTime = getEpochTime();

    //create Background Subtractor objects - aka. a running average image
    pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach

	//Pause for half second between images
	normalSleepTime = 500000;
	//25 FPS (ideal, but depends on hardware speed)
	filmingSleepTime = 40000;

	if (!Camera.open()) {
		cerr << "Error opening the camera" << endl;
		return -1;
	}

	run();

	Camera.release();

    return EXIT_SUCCESS;
}

/**
 * Main loop, which runs normal detection and image saving
 */
void run() {

    while(true){

		Mat frame = shootImage();

		//If the system has detected motion, it saves it by single image
		//Theoretically it films at speed of 25, but image saveing is slow
		//operation, which lowers fps. Image quality over quantity
		if(isFilmingMode) {
			saveImage(frame);

			long timeSeparation = getEpochTime() - detectionTime;

			if(timeSeparation > recordTime) {
				isFilmingMode = false;
			}
			else {
				usleep(filmingSleepTime);
			}
		}
		else {
			isFilmingMode = checkFrame(frame);

			//Prevent false alarms at first 5 seconds
			if(getEpochTime() - startingTime < 5) {
				isFilmingMode = false;
			}

			//if the situation has not changed,
			//keep a pause
			if(!isFilmingMode) {
				usleep(normalSleepTime);
			}
			else {
				detectionTime = getEpochTime();
			}

		}

    }

}

/**
 * Image comparator. Compares image to the running average,
 * and if it notices too big differences, it returns true -value
 * @param  frame OpenCV-matrix image
 * @return       Bool - tells if motion is detected
 */
bool checkFrame(Mat frame) {
	Mat blurFrame;

	bool motionDetected = false;

	//Turn the image to gray
	cvtColor(frame, blurFrame, CV_BGR2GRAY );

	//Blur it
	GaussianBlur( blurFrame, blurFrame, Size( 21, 21 ), 0, 0 );

	//update the background model and set a comparsion image
	//comparsion image will be black, except if there was differences
	//between images. Then diffs are gray
	pMOG2->apply(blurFrame, fgMaskMOG2);


	//The first frame must be skipped, or it will cause a false alarm
	if(!firstFrameEncountered) {
		firstFrameEncountered = true;
	}

	else {

		//Gray to white
		threshold(fgMaskMOG2, blurFrame, 5.0d, 255, THRESH_BINARY);

		Mat element = getStructuringElement( MORPH_RECT,
			Size( 21, 21 ),
			Point( 10, 10 ) );

		//Bold white areas
		dilate(blurFrame, blurFrame, element, Point( -1, -1 ), 2);

		vector<vector<Point>> contours;

		//Check, if shapes are bigger than the limit value
		findContours(blurFrame, contours, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE );

		for (int i = 0; i < contours.size(); i++){

			//Movement detected, if contours are too big
			if(contourArea(contours[i]) > detectionArea) {

				motionDetected = true;
				break;
			}
		}
	}

	return motionDetected;
}

/**
 * Saves an image named as current timestamp and
 * prints it's name to to stdstream
 *
 * @param frame OpenCV -matrix containing a photo
 */
void saveImage(Mat frame) {
	auto now = std::chrono::system_clock::now();
	auto now_ms = std::chrono::time_point_cast<std::chrono::milliseconds>(now);

	auto value = now_ms.time_since_epoch();
	unsigned long duration = value.count();

	string name = to_string(duration) + ".jpg";
	if(imwrite("images/" + name, frame)) {
		cout << name << endl;
	}

	/* TODO: send a photo as binary to stdout or something
	*  without saving it
	vector<uchar> buf(50000);
	imencode(".jpg", frame, buf);
	*/
}

/**
 * @return OpenCV Matrix containing a photo
 * taken by Rpi Camera
 */
Mat shootImage() {
	Mat img;

	Camera.grab();
	Camera.retrieve(img);

	return img;
}

/**
 * @return Current Unix timestamp
 */
unsigned long getEpochTime() {
	using namespace std::chrono;
	auto now = system_clock::now();
	auto now_s = time_point_cast<seconds>(now);

	auto value = now_s.time_since_epoch();
	unsigned long duration = value.count();
	return duration;
}